{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TJem_sS9FqbP"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "2k_IUAtTcIhj",
        "outputId": "cdfdb1cb-3ad6-4b32-f548-537846cee485"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting anvil-uplink\n",
            "  Downloading anvil_uplink-0.3.42-py2.py3-none-any.whl (64 kB)\n",
            "\u001b[K     |████████████████████████████████| 64 kB 2.3 MB/s \n",
            "\u001b[?25hCollecting argparse\n",
            "  Downloading argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from anvil-uplink) (1.15.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from anvil-uplink) (0.16.0)\n",
            "Collecting ws4py\n",
            "  Downloading ws4py-0.5.1.tar.gz (51 kB)\n",
            "\u001b[K     |████████████████████████████████| 51 kB 186 kB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: ws4py\n",
            "  Building wheel for ws4py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ws4py: filename=ws4py-0.5.1-py3-none-any.whl size=45229 sha256=b68b43923a3a13eb96adb4edc07322e1e60cb65bad5207a05bf4149c61137e85\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/ea/7d/3410aa0aa0e4402ead9a7a97ab2214804887e0f5c2b76f0c96\n",
            "Successfully built ws4py\n",
            "Installing collected packages: ws4py, argparse, anvil-uplink\n",
            "Successfully installed anvil-uplink-0.3.42 argparse-1.4.0 ws4py-0.5.1\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "argparse",
                  "google"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install anvil-uplink"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "QZcN-Th7gwpI"
      },
      "outputs": [],
      "source": [
        "uplink_key = \"server_ADKLTUCFGN3IHEVSRW6P3KPZ-KU6UZX5W6LMFGNKI\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "TELB_6decTKo",
        "outputId": "c62f3799-3ed1-4ed4-a138-b4822b9eacf6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Connecting to wss://anvil.works/uplink\n",
            "Anvil websocket open\n",
            "Connected to \"Published\" as SERVER\n"
          ]
        }
      ],
      "source": [
        "import anvil.server\n",
        "\n",
        "anvil.server.connect(uplink_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JEWaUJru6R_U",
        "outputId": "d46835c8-c94d-4273-9183-aca9ce9cf17a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting text2emotion\n",
            "  Downloading text2emotion-0.0.5-py3-none-any.whl (57 kB)\n",
            "\u001b[?25l\r\u001b[K     |█████▊                          | 10 kB 22.9 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 20 kB 27.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 30 kB 23.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 40 kB 19.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 51 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 57 kB 4.3 MB/s \n",
            "\u001b[?25hCollecting emoji>=0.6.0\n",
            "  Downloading emoji-1.7.0.tar.gz (175 kB)\n",
            "\u001b[K     |████████████████████████████████| 175 kB 19.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from text2emotion) (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->text2emotion) (1.15.0)\n",
            "Building wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-1.7.0-py3-none-any.whl size=171046 sha256=9d3f596a5ce1c6553f18f3de878373e9abdbae4de18c38ea23b048fe322f2d84\n",
            "  Stored in directory: /root/.cache/pip/wheels/8a/4e/b6/57b01db010d17ef6ea9b40300af725ef3e210cb1acfb7ac8b6\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji, text2emotion\n",
            "Successfully installed emoji-1.7.0 text2emotion-0.0.5\n"
          ]
        }
      ],
      "source": [
        "!pip install text2emotion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZUoGYAazgse",
        "outputId": "53e1bd23-8792-4659-889f-34e122d70e38"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        }
      ],
      "source": [
        "from pydoc import doc\n",
        "import re \n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "import text2emotion as te"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtAwRcgq0oir",
        "outputId": "5a1c7bfe-156a-4050-8ebb-0597482a7fe6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "import json\n",
        "import pickle\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O6kGcc4Qz58h"
      },
      "outputs": [],
      "source": [
        "# pip install tensorflow keras pickle nltk\n",
        "from google.colab import drive\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout\n",
        "# from keras.optimizers import SGD\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "import random\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "import json\n",
        "import pickle\n",
        "intents_file = open('/content/drive/MyDrive/Colab Notebooks/intents.json').read()\n",
        "intents = json.loads(intents_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MOlYh5OC1FE-",
        "outputId": "b26145cc-c31a-4b6a-8eb3-d8406a715950"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[(['hi'], 'greeting'), (['hello'], 'greeting'), (['hai'], 'greeting'), (['helloo'], 'greeting'), (['hlo'], 'greeting'), (['hloii'], 'greeting'), (['whats', 'up'], 'greeting'), (['sup'], 'greeting'), (['is', 'anyone', 'there'], 'greeting'), (['hey'], 'greeting'), (['bye'], 'goodbye'), (['cya'], 'goodbye'), (['see', 'you', 'later'], 'goodbye'), (['goodbye'], 'goodbye'), (['im', 'leaving'], 'goodbye'), (['have', 'a', 'good', 'day'], 'goodbye'), (['how', 'old', 'are', 'you'], 'age'), (['what', 'is', 'your', 'age'], 'age'), (['thanks'], 'thanks'), (['thank', 'you'], 'thanks'), (['thankyou'], 'thanks'), (['ty'], 'thanks'), (['I', 'owe', 'you', 'one'], 'thanks'), (['whats', 'is', 'your', 'name'], 'name'), (['whats', 'your', 'name'], 'name'), (['whats', 'should', 'I', 'call', 'you'], 'name'), (['how', 'should', 'I', 'address', 'you'], 'name'), (['Yes', 'it', 'does'], 'sky_net_yes'), (['Yeah'], 'sky_net_yes'), (['Haha', 'yep'], 'sky_net_yes'), (['yes'], 'sky_net_yes'), (['Indeed'], 'sky_net_yes'), (['Yup'], 'sky_net_yes'), (['no'], 'sky_net_no'), (['nah'], 'sky_net_no'), (['not', 'really'], 'sky_net_no'), (['nope'], 'sky_net_no'), (['how', 'are', 'you'], 'how_are_you'), (['how', 'are', 'you', 'doing'], 'how_are_you'), (['what', 'is', 'going', 'on'], 'how_are_you'), (['are', 'you', 'good'], 'how_are_you'), (['u', 'good'], 'how_are_you'), (['are', 'u', 'good'], 'how_are_you'), (['are', 'you', 'okay'], 'how_are_you'), (['I', 'am', 'doing', 'great'], 'doing_great'), (['it', 'was', 'a', 'good', 'day'], 'doing_great'), (['I', 'am', 'well'], 'doing_great'), (['Im', 'great'], 'doing_great'), (['awesome'], 'doing_great'), (['happy'], 'doing_great'), (['better'], 'doing_great'), (['fyn'], 'doing_great'), (['fine'], 'doing_great'), (['good', 'day'], 'doing_great'), (['glad', 'to', 'meet', 'you'], 'doing_great'), (['it', 'was', 'so', 'good'], 'doing_great'), (['not', 'great'], 'doing_badly'), (['not', 'well'], 'doing_badly'), (['not', 'good'], 'doing_badly'), (['bad'], 'doing_badly'), (['badly'], 'doing_badly'), (['terrible'], 'doing_badly'), (['horrible'], 'doing_badly'), (['awful'], 'doing_badly'), (['sad'], 'doing_badly'), (['it', 'was', 'so', 'bad'], 'doing_badly'), (['bad', 'day'], 'doing_badly'), (['im', 'so', 'sad'], 'doing_badly'), (['wait', 'you', 'watch', 'Netflix'], 'netflix'), (['how', 'do', 'you', 'watch', 'Netflix'], 'netflix'), (['Netflix'], 'netflix'), (['how', 'can', 'you', 'run'], 'quick_run'), (['how', 'do', 'you', 'run'], 'quick_run'), (['how', 'run'], 'quick_run'), (['why', 'run'], 'quick_run'), (['run'], 'quick_run'), (['you', 'real'], 'real_bot'), (['you', 'human'], 'real_bot'), (['you', 'robot'], 'real_bot'), (['you', 'alive'], 'real_bot'), (['you', 'sentient'], 'real_bot'), (['you', 'conscious'], 'real_bot'), (['tell', 'me', 'joke'], 'joke'), (['got', 'any', 'good', 'jokes'], 'joke'), (['got', 'jokes'], 'joke'), (['can', 'you', 'tell', 'joke'], 'joke'), (['tell', 'joke'], 'joke'), (['haha'], 'good_joke'), (['that', 'was', 'funny'], 'good_joke'), (['very', 'funny'], 'good_joke'), (['good', 'one'], 'good_joke'), (['bad', 'joke'], 'bad_joke'), (['trash', 'joke'], 'bad_joke'), (['terrible'], 'bad_joke'), (['not', 'funny'], 'bad_joke'), (['I', 'hate', 'you'], 'hate'), (['you', 'stupid'], 'hate'), (['you', 'dumb'], 'hate'), (['you', 'mean'], 'hate'), (['i', 'do', \"n't\", 'like', 'you'], 'hate'), (['you', 'my', 'friend'], 'like'), (['I', 'like', 'you'], 'like'), (['I', 'love', 'you'], 'like'), (['you', 'cool'], 'like'), (['you', 'are', 'chill'], 'like'), (['it', 'is', 'nice', 'chatting', 'with', 'you'], 'like'), (['whats', 'favorite', 'show'], 'favorite_show'), (['favorite', 'tv', 'show'], 'favorite_show'), (['Whats', 'favorite', 'movie'], 'favorite_movie'), (['whats', 'favorite', 'film'], 'favorite_movie'), (['best', 'movie'], 'favorite_movie'), (['your', 'favorite', 'movie'], 'favorite_movie'), (['whats', 'your', 'favorite', 'movie'], 'favorite_movie'), (['What', 'think', 'about'], 'your_thoughts'), (['What', 'your', 'thoughts'], 'your_thoughts'), (['i', 'am', 'so', 'scared'], 'fear'), (['that', \"'s\", 'scary'], 'fear'), (['aaaaa'], 'excitement'), (['hkfjj'], 'excitement'), (['gjlfoiodso'], 'excitement'), (['cbbmlkllll'], 'excitement'), (['fieueiioohd'], 'excitement'), (['ohhhhhhhhh'], 'excitement'), (['bbbbb'], 'excitement'), (['cccc'], 'excitement'), (['vvvv'], 'excitement'), (['ddddd'], 'excitement'), (['eeee'], 'excitement'), (['ffff'], 'excitement'), (['ggggg'], 'excitement'), (['hhh'], 'excitement'), (['iiii'], 'excitement'), (['jjjj'], 'excitement'), (['llll'], 'excitement'), (['nnnnn'], 'excitement'), (['pppp'], 'excitement'), (['qqqq'], 'excitement'), (['rrrr'], 'excitement'), (['tttt'], 'excitement'), (['vvvv'], 'excitement'), (['wwww'], 'excitement'), (['xxx'], 'excitement'), (['kkk'], 'character_sp'), (['sss'], 'character_sp'), (['oooo'], 'character_sp'), (['zzzz'], 'character_sl'), (['fine'], 'fine'), (['i', 'am', 'fine'], 'fine'), (['you', 'are', 'cute'], 'cute'), (['you', 'so', 'beautifull'], 'cute'), (['eww'], 'disgust'), (['it', \"'s\", 'so', 'disgusting'], 'disgust'), (['disgust'], 'disgust'), (['disgusting'], 'disgust'), (['it', 'was', 'disgusting'], 'disgust'), (['you', 'are', 'so', 'annoying'], 'angry'), (['you', 'idiot'], 'angry'), ([',', '#', '$', '%', '^', '&'], 'angry'), (['$', '$', '#', '^'], 'angry'), (['%', '%', '$', '#', '^'], 'angry'), (['^', '$', '#', '%'], 'angry'), (['!', '#', '@'], 'angry'), (['i', 'am', 'so', 'ashamed', 'of', 'myself'], 'shame'), (['i', 'am', 'a', 'loser'], 'shame'), (['shame'], 'shame'), (['shame', 'of', 'you'], 'shame'), (['it', \"'s\", 'because', 'of', 'me'], 'guilt'), (['i', 'am', 'the', 'reason'], 'guilt'), (['i', 'am', 'so', 'cruel'], 'guilt'), (['i', 'feel', 'guilty'], 'guilt'), (['guilt'], 'guilt'), (['i', 'am', 'the', 'one', 'to', 'be', 'punished'], 'guilt')]\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "words=[]\n",
        "classes = []\n",
        "documents = []\n",
        "ignore_letters = ['!', '?', ',', '.']\n",
        "for intent in intents['intents']:\n",
        "    for pattern in intent['patterns']:\n",
        "        #tokenize each word\n",
        "        word = nltk.word_tokenize(pattern)\n",
        "        words.extend(word)\n",
        "        #add documents in the corpus\n",
        "        documents.append((word, intent['tag']))\n",
        "        # add to our classes list\n",
        "        if intent['tag'] not in classes:\n",
        "            classes.append(intent['tag'])\n",
        "print(documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQmkYrce2APb",
        "outputId": "d7883e2a-1ce9-422a-a62c-d6e05f7eeea2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "Training data is created\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:25: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "# create the training data\n",
        "training = []\n",
        "# create empty array for the output\n",
        "output_empty = [0] * len(classes)\n",
        "# training set, bag of words for every sentence\n",
        "for doc in documents:\n",
        "    # initializing bag of words\n",
        "\n",
        "    bag = []\n",
        "    # list of tokenized words for the pattern\n",
        "    word_patterns = doc[0]\n",
        "    # lemmatize each word - create base word, in attempt to represent related words\n",
        "    word_patterns = [lemmatizer.lemmatize(word.lower()) for word in word_patterns]\n",
        "    # create the bag of words array with 1, if word is found in current pattern\n",
        "    for word in words:\n",
        "        bag.append(1) if word in word_patterns else bag.append(0)\n",
        "    # output is a '0' for each tag and '1' for current tag (for each pattern)\n",
        "    output_row = list(output_empty)\n",
        "    output_row[classes.index(doc[1])] = 1 #\n",
        "    training.append([bag, output_row])\n",
        "# shuffle the features and make numpy array\n",
        "random.shuffle(training)\n",
        "training = np.array(training)\n",
        "# create training and testing lists. X - patterns, Y - intents\n",
        "train_x = list(training[:,0])\n",
        "train_y = list(training[:,1])\n",
        "print(\"Training data is created\")\n",
        "#print(train_x)\n",
        "#print(train_y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npkB3-YC0lxX"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5SaLoZJ2kpo",
        "outputId": "df116e1c-5529-4c4a-d611-2b333c418182"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "35/35 [==============================] - 1s 3ms/step - loss: 3.4289 - accuracy: 0.0988\n",
            "Epoch 2/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 3.2703 - accuracy: 0.1744\n",
            "Epoch 3/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 3.0960 - accuracy: 0.2151\n",
            "Epoch 4/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 2.9237 - accuracy: 0.2267\n",
            "Epoch 5/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 2.7718 - accuracy: 0.2907\n",
            "Epoch 6/200\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 2.5996 - accuracy: 0.3023\n",
            "Epoch 7/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 2.5338 - accuracy: 0.3140\n",
            "Epoch 8/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 2.4610 - accuracy: 0.3314\n",
            "Epoch 9/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 2.3381 - accuracy: 0.3605\n",
            "Epoch 10/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 2.2998 - accuracy: 0.3430\n",
            "Epoch 11/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 2.2634 - accuracy: 0.3837\n",
            "Epoch 12/200\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 2.2017 - accuracy: 0.3779\n",
            "Epoch 13/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 2.0897 - accuracy: 0.4186\n",
            "Epoch 14/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 2.0751 - accuracy: 0.3837\n",
            "Epoch 15/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 2.1127 - accuracy: 0.3895\n",
            "Epoch 16/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.9481 - accuracy: 0.4360\n",
            "Epoch 17/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.9431 - accuracy: 0.4244\n",
            "Epoch 18/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.8500 - accuracy: 0.4477\n",
            "Epoch 19/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.7722 - accuracy: 0.4767\n",
            "Epoch 20/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.7532 - accuracy: 0.4244\n",
            "Epoch 21/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.6437 - accuracy: 0.4826\n",
            "Epoch 22/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.7964 - accuracy: 0.4651\n",
            "Epoch 23/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.6377 - accuracy: 0.4709\n",
            "Epoch 24/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.7995 - accuracy: 0.4419\n",
            "Epoch 25/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.5166 - accuracy: 0.5174\n",
            "Epoch 26/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.6656 - accuracy: 0.5291\n",
            "Epoch 27/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.4696 - accuracy: 0.5407\n",
            "Epoch 28/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.4267 - accuracy: 0.5988\n",
            "Epoch 29/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.4728 - accuracy: 0.6047\n",
            "Epoch 30/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.4313 - accuracy: 0.5988\n",
            "Epoch 31/200\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 1.4311 - accuracy: 0.5523\n",
            "Epoch 32/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.3607 - accuracy: 0.5872\n",
            "Epoch 33/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.3177 - accuracy: 0.6047\n",
            "Epoch 34/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.3116 - accuracy: 0.6279\n",
            "Epoch 35/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.2437 - accuracy: 0.6453\n",
            "Epoch 36/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.2818 - accuracy: 0.6628\n",
            "Epoch 37/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.2416 - accuracy: 0.6279\n",
            "Epoch 38/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.2969 - accuracy: 0.5930\n",
            "Epoch 39/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.2574 - accuracy: 0.6279\n",
            "Epoch 40/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.0618 - accuracy: 0.6977\n",
            "Epoch 41/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.4742 - accuracy: 0.6047\n",
            "Epoch 42/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.1030 - accuracy: 0.6570\n",
            "Epoch 43/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.1389 - accuracy: 0.6628\n",
            "Epoch 44/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.1071 - accuracy: 0.6919\n",
            "Epoch 45/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.0531 - accuracy: 0.6802\n",
            "Epoch 46/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.0668 - accuracy: 0.6802\n",
            "Epoch 47/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.0837 - accuracy: 0.6744\n",
            "Epoch 48/200\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.9596 - accuracy: 0.7267\n",
            "Epoch 49/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.0024 - accuracy: 0.7093\n",
            "Epoch 50/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.0191 - accuracy: 0.6744\n",
            "Epoch 51/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.0132 - accuracy: 0.6919\n",
            "Epoch 52/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9148 - accuracy: 0.7442\n",
            "Epoch 53/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.0039 - accuracy: 0.6860\n",
            "Epoch 54/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9651 - accuracy: 0.7209\n",
            "Epoch 55/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.1034 - accuracy: 0.6860\n",
            "Epoch 56/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.0314 - accuracy: 0.6570\n",
            "Epoch 57/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9615 - accuracy: 0.6802\n",
            "Epoch 58/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8767 - accuracy: 0.7558\n",
            "Epoch 59/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9672 - accuracy: 0.6919\n",
            "Epoch 60/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9210 - accuracy: 0.7326\n",
            "Epoch 61/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.0343 - accuracy: 0.7151\n",
            "Epoch 62/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8531 - accuracy: 0.7384\n",
            "Epoch 63/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8578 - accuracy: 0.7442\n",
            "Epoch 64/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9092 - accuracy: 0.7093\n",
            "Epoch 65/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.0360 - accuracy: 0.6919\n",
            "Epoch 66/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.0159 - accuracy: 0.7035\n",
            "Epoch 67/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8908 - accuracy: 0.7558\n",
            "Epoch 68/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.7901 - accuracy: 0.7442\n",
            "Epoch 69/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8825 - accuracy: 0.7035\n",
            "Epoch 70/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9155 - accuracy: 0.6977\n",
            "Epoch 71/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.0851 - accuracy: 0.6919\n",
            "Epoch 72/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9086 - accuracy: 0.6802\n",
            "Epoch 73/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8961 - accuracy: 0.7326\n",
            "Epoch 74/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9888 - accuracy: 0.7209\n",
            "Epoch 75/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9809 - accuracy: 0.6860\n",
            "Epoch 76/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9699 - accuracy: 0.6744\n",
            "Epoch 77/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.0763 - accuracy: 0.7093\n",
            "Epoch 78/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8403 - accuracy: 0.7326\n",
            "Epoch 79/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8090 - accuracy: 0.7500\n",
            "Epoch 80/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9329 - accuracy: 0.7151\n",
            "Epoch 81/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.7028 - accuracy: 0.7558\n",
            "Epoch 82/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8295 - accuracy: 0.7209\n",
            "Epoch 83/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.7972 - accuracy: 0.7500\n",
            "Epoch 84/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8786 - accuracy: 0.7267\n",
            "Epoch 85/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8995 - accuracy: 0.7267\n",
            "Epoch 86/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9079 - accuracy: 0.7442\n",
            "Epoch 87/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.7559 - accuracy: 0.7326\n",
            "Epoch 88/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9704 - accuracy: 0.7093\n",
            "Epoch 89/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8492 - accuracy: 0.7326\n",
            "Epoch 90/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.0551 - accuracy: 0.7035\n",
            "Epoch 91/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.7750 - accuracy: 0.7558\n",
            "Epoch 92/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.7935 - accuracy: 0.7209\n",
            "Epoch 93/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8554 - accuracy: 0.7326\n",
            "Epoch 94/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9118 - accuracy: 0.7209\n",
            "Epoch 95/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8637 - accuracy: 0.7267\n",
            "Epoch 96/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.7933 - accuracy: 0.7384\n",
            "Epoch 97/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.7834 - accuracy: 0.7558\n",
            "Epoch 98/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6535 - accuracy: 0.7791\n",
            "Epoch 99/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6848 - accuracy: 0.7849\n",
            "Epoch 100/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8631 - accuracy: 0.6802\n",
            "Epoch 101/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8078 - accuracy: 0.7616\n",
            "Epoch 102/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6360 - accuracy: 0.8023\n",
            "Epoch 103/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.7075 - accuracy: 0.7733\n",
            "Epoch 104/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.7986 - accuracy: 0.7733\n",
            "Epoch 105/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8654 - accuracy: 0.7267\n",
            "Epoch 106/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8433 - accuracy: 0.7500\n",
            "Epoch 107/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6539 - accuracy: 0.7849\n",
            "Epoch 108/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.7974 - accuracy: 0.7500\n",
            "Epoch 109/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.7539 - accuracy: 0.7326\n",
            "Epoch 110/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.7813 - accuracy: 0.7558\n",
            "Epoch 111/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.7388 - accuracy: 0.7733\n",
            "Epoch 112/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6580 - accuracy: 0.7674\n",
            "Epoch 113/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6331 - accuracy: 0.8023\n",
            "Epoch 114/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.7798 - accuracy: 0.7849\n",
            "Epoch 115/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8182 - accuracy: 0.7442\n",
            "Epoch 116/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8507 - accuracy: 0.6919\n",
            "Epoch 117/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8352 - accuracy: 0.7209\n",
            "Epoch 118/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.7119 - accuracy: 0.8023\n",
            "Epoch 119/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.7620 - accuracy: 0.7674\n",
            "Epoch 120/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6768 - accuracy: 0.7791\n",
            "Epoch 121/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6774 - accuracy: 0.7616\n",
            "Epoch 122/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.7623 - accuracy: 0.7442\n",
            "Epoch 123/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6376 - accuracy: 0.7616\n",
            "Epoch 124/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.7255 - accuracy: 0.7442\n",
            "Epoch 125/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.7787 - accuracy: 0.7384\n",
            "Epoch 126/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6716 - accuracy: 0.7558\n",
            "Epoch 127/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.7026 - accuracy: 0.7733\n",
            "Epoch 128/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.7606 - accuracy: 0.7442\n",
            "Epoch 129/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6811 - accuracy: 0.7791\n",
            "Epoch 130/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.7858 - accuracy: 0.7326\n",
            "Epoch 131/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.7217 - accuracy: 0.7674\n",
            "Epoch 132/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8291 - accuracy: 0.7326\n",
            "Epoch 133/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5799 - accuracy: 0.8081\n",
            "Epoch 134/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.7285 - accuracy: 0.7558\n",
            "Epoch 135/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.7208 - accuracy: 0.7733\n",
            "Epoch 136/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6596 - accuracy: 0.7616\n",
            "Epoch 137/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5537 - accuracy: 0.8023\n",
            "Epoch 138/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6536 - accuracy: 0.7733\n",
            "Epoch 139/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6718 - accuracy: 0.7674\n",
            "Epoch 140/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6491 - accuracy: 0.8023\n",
            "Epoch 141/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6925 - accuracy: 0.7907\n",
            "Epoch 142/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.7804 - accuracy: 0.7558\n",
            "Epoch 143/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6809 - accuracy: 0.7674\n",
            "Epoch 144/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.7781 - accuracy: 0.7500\n",
            "Epoch 145/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6561 - accuracy: 0.7849\n",
            "Epoch 146/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6002 - accuracy: 0.8314\n",
            "Epoch 147/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9569 - accuracy: 0.7384\n",
            "Epoch 148/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6996 - accuracy: 0.7616\n",
            "Epoch 149/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.7723 - accuracy: 0.7500\n",
            "Epoch 150/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.7300 - accuracy: 0.7674\n",
            "Epoch 151/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6786 - accuracy: 0.7558\n",
            "Epoch 152/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5737 - accuracy: 0.8140\n",
            "Epoch 153/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6011 - accuracy: 0.8198\n",
            "Epoch 154/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6528 - accuracy: 0.7907\n",
            "Epoch 155/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5462 - accuracy: 0.8198\n",
            "Epoch 156/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5903 - accuracy: 0.7849\n",
            "Epoch 157/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.7687 - accuracy: 0.7558\n",
            "Epoch 158/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.7082 - accuracy: 0.7733\n",
            "Epoch 159/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6523 - accuracy: 0.7616\n",
            "Epoch 160/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6418 - accuracy: 0.7849\n",
            "Epoch 161/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.7807 - accuracy: 0.7674\n",
            "Epoch 162/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.7905 - accuracy: 0.7500\n",
            "Epoch 163/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6800 - accuracy: 0.7791\n",
            "Epoch 164/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6035 - accuracy: 0.8198\n",
            "Epoch 165/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5907 - accuracy: 0.7965\n",
            "Epoch 166/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6000 - accuracy: 0.7791\n",
            "Epoch 167/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5536 - accuracy: 0.8198\n",
            "Epoch 168/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5533 - accuracy: 0.8256\n",
            "Epoch 169/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.7024 - accuracy: 0.7733\n",
            "Epoch 170/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6404 - accuracy: 0.8140\n",
            "Epoch 171/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6741 - accuracy: 0.7616\n",
            "Epoch 172/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5669 - accuracy: 0.7733\n",
            "Epoch 173/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6448 - accuracy: 0.7791\n",
            "Epoch 174/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.7057 - accuracy: 0.7558\n",
            "Epoch 175/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6055 - accuracy: 0.8081\n",
            "Epoch 176/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6076 - accuracy: 0.7791\n",
            "Epoch 177/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.7547 - accuracy: 0.7674\n",
            "Epoch 178/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.7540 - accuracy: 0.7558\n",
            "Epoch 179/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.7674\n",
            "Epoch 180/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6357 - accuracy: 0.7791\n",
            "Epoch 181/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6706 - accuracy: 0.7558\n",
            "Epoch 182/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5365 - accuracy: 0.8140\n",
            "Epoch 183/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6242 - accuracy: 0.8023\n",
            "Epoch 184/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6040 - accuracy: 0.7965\n",
            "Epoch 185/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5654 - accuracy: 0.7791\n",
            "Epoch 186/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6701 - accuracy: 0.7965\n",
            "Epoch 187/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6154 - accuracy: 0.8140\n",
            "Epoch 188/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6154 - accuracy: 0.7965\n",
            "Epoch 189/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.7040 - accuracy: 0.7558\n",
            "Epoch 190/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5908 - accuracy: 0.7965\n",
            "Epoch 191/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6222 - accuracy: 0.7674\n",
            "Epoch 192/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5625 - accuracy: 0.8140\n",
            "Epoch 193/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6646 - accuracy: 0.7907\n",
            "Epoch 194/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6175 - accuracy: 0.7791\n",
            "Epoch 195/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6697 - accuracy: 0.7674\n",
            "Epoch 196/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6414 - accuracy: 0.7849\n",
            "Epoch 197/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5707 - accuracy: 0.7965\n",
            "Epoch 198/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.7145 - accuracy: 0.7791\n",
            "Epoch 199/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6768 - accuracy: 0.7674\n",
            "Epoch 200/200\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6103 - accuracy: 0.7849\n",
            "model is created\n"
          ]
        }
      ],
      "source": [
        "# deep neural networds model KERAS\n",
        "model = Sequential()\n",
        "model.add(Dense(128, input_shape=(len(train_x[0]),), activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(len(train_y[0]), activation='softmax'))\n",
        "# Compiling model. SGD with Nesterov accelerated gradient gives good results for this model\n",
        "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True) #optimizer \n",
        "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "#Training and saving the model \n",
        "hist = model.fit(np.array(train_x), np.array(train_y), epochs=200, batch_size=5, verbose=1)\n",
        "model.save('chatbot_model.h5', hist)\n",
        "print(\"model is created\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXMRMVuEhs9z",
        "outputId": "738af2cf-63b0-4900-85a5-ef2e6234f088"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 128)               50432     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 31)                2015      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 60,703\n",
            "Trainable params: 60,703\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        " model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vnPze0wTmN6i"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 644
        },
        "id": "nZcXb0Z5loLK",
        "outputId": "19cab3a6-9ece-432e-c1a7-48d3c5912601"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.keras.utils.plot_model(model,to_file='simple.png',show_shapes=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "chIZ8fT222Lo"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "import pickle\n",
        "import numpy as np\n",
        "from keras.models import load_model\n",
        "model = load_model('chatbot_model.h5')\n",
        "import json\n",
        "import random\n",
        "intents = json.loads(open('/content/drive/MyDrive/Colab Notebooks/intents.json').read())\n",
        "words = pickle.load(open('/content/drive/MyDrive/Colab Notebooks/words.pkl','rb'))\n",
        "classes = pickle.load(open('/content/drive/MyDrive/Colab Notebooks/classes.pkl','rb'))\n",
        "def clean_up_sentence(sentence):\n",
        "    # tokenize the pattern - splitting words into array\n",
        "    sentence_words = nltk.word_tokenize(sentence)\n",
        "    # stemming every word - reducing to base form\n",
        "    sentence_words = [lemmatizer.lemmatize(word.lower()) for word in sentence_words]\n",
        "    return sentence_words\n",
        "# return bag of words array: 0 or 1 for words that exist in sentence\n",
        "def bag_of_words(sentence, words, show_details=True):\n",
        "    # tokenizing patterns\n",
        "    sentence_words = clean_up_sentence(sentence)\n",
        "    # bag of words - vocabulary matrix\n",
        "    bag = [0]*len(words)  \n",
        "    for s in sentence_words:\n",
        "        for i,word in enumerate(words):\n",
        "            if word == s: \n",
        "                # assign 1 if current word is in the vocabulary position\n",
        "                bag[i] = 1\n",
        "                if show_details:\n",
        "                    print (\"found in bag: %s\" % word)\n",
        "    return(np.array(bag))\n",
        "def predict_class(sentence):\n",
        "    # filter below  threshold predictions\n",
        "    p = bag_of_words(sentence, words,show_details=False)\n",
        "    res = model.predict(np.array([p]))[0]\n",
        "    ERROR_THRESHOLD = 0.25\n",
        "    results = [[i,r] for i,r in enumerate(res) if r>ERROR_THRESHOLD]\n",
        "    # sorting strength probability\n",
        "    results.sort(key=lambda x: x[1], reverse=True)\n",
        "    return_list = []\n",
        "    for r in results:\n",
        "        return_list.append({\"intent\": classes[r[0]], \"probability\": str(r[1])})\n",
        "    return return_list\n",
        "def getResponse(ints, intents_json):\n",
        "    tag = ints[0]['intent']\n",
        "    list_of_intents = intents_json['intents']\n",
        "    for i in list_of_intents:\n",
        "        if(i['tag']== tag):\n",
        "            result = random.choice(i['responses'])\n",
        "            break\n",
        "    return result\n",
        "#Creating tkinter GUI\n",
        "# import tkinter\n",
        "# from tkinter import *\n",
        "# def send():\n",
        "#     msg = EntryBox.get(\"1.0\",'end-1c').strip()\n",
        "#     EntryBox.delete(\"0.0\",END)\n",
        "#     if msg != '':\n",
        "#         ChatBox.config(state=NORMAL)\n",
        "#         ChatBox.insert(END, \"You: \" + msg + '\\n\\n')\n",
        "#         ChatBox.config(foreground=\"#446665\", font=(\"Verdana\", 12 )) \n",
        "#         ints = predict_class(msg)\n",
        "#         res = getResponse(ints, intents)\n",
        "#         ChatBox.insert(END, \"Bot: \" + res + '\\n\\n')           \n",
        "#         ChatBox.config(state=DISABLED)\n",
        "#         ChatBox.yview(END)\n",
        "# root = Tk()\n",
        "# root.title(\"Chatbot\")\n",
        "# root.geometry(\"400x500\")\n",
        "# root.resizable(width=FALSE, height=FALSE)\n",
        "# #Create Chat window\n",
        "# ChatBox = Text(root, bd=0, bg=\"white\", height=\"8\", width=\"50\", font=\"Arial\",)\n",
        "# ChatBox.config(state=DISABLED)\n",
        "# #Bind scrollbar to Chat window\n",
        "# scrollbar = Scrollbar(root, command=ChatBox.yview, cursor=\"heart\")\n",
        "# ChatBox['yscrollcommand'] = scrollbar.set\n",
        "# #Create Button to send message\n",
        "# SendButton = Button(root, font=(\"Verdana\",12,'bold'), text=\"Send\", width=\"12\", height=5,\n",
        "#                     bd=0, bg=\"#f9a602\", activebackground=\"#3c9d9b\",fg='#000000',\n",
        "#                     command= send )\n",
        "# #Create the box to enter message\n",
        "# EntryBox = Text(root, bd=0, bg=\"white\",width=\"29\", height=\"5\", font=\"Arial\")\n",
        "# #EntryBox.bind(\"<Return>\", send)\n",
        "# #Place all components on the screen\n",
        "# scrollbar.place(x=376,y=6, height=386)\n",
        "# ChatBox.place(x=6,y=6, height=386, width=370)\n",
        "# EntryBox.place(x=128, y=401, height=90, width=265)\n",
        "# SendButton.place(x=6, y=401, height=90)\n",
        "# root.mainloop()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "naiGxGhK7wgu",
        "outputId": "52a71d07-e5c1-4b60-ba8a-18e089d81cfc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[(['hi'], 'greeting'), (['hello'], 'greeting'), (['hai'], 'greeting'), (['helloo'], 'greeting'), (['hlo'], 'greeting'), (['hloii'], 'greeting'), (['whats', 'up'], 'greeting'), (['sup'], 'greeting'), (['is', 'anyone', 'there'], 'greeting'), (['hey'], 'greeting'), (['bye'], 'goodbye'), (['cya'], 'goodbye'), (['see', 'you', 'later'], 'goodbye'), (['goodbye'], 'goodbye'), (['im', 'leaving'], 'goodbye'), (['have', 'a', 'good', 'day'], 'goodbye'), (['how', 'old', 'are', 'you'], 'age'), (['what', 'is', 'your', 'age'], 'age'), (['thanks'], 'thanks'), (['thank', 'you'], 'thanks'), (['thankyou'], 'thanks'), (['ty'], 'thanks'), (['I', 'owe', 'you', 'one'], 'thanks'), (['whats', 'is', 'your', 'name'], 'name'), (['whats', 'your', 'name'], 'name'), (['whats', 'should', 'I', 'call', 'you'], 'name'), (['how', 'should', 'I', 'address', 'you'], 'name'), (['Yes', 'it', 'does'], 'sky_net_yes'), (['Yeah'], 'sky_net_yes'), (['Haha', 'yep'], 'sky_net_yes'), (['yes'], 'sky_net_yes'), (['Indeed'], 'sky_net_yes'), (['Yup'], 'sky_net_yes'), (['no'], 'sky_net_no'), (['nah'], 'sky_net_no'), (['not', 'really'], 'sky_net_no'), (['nope'], 'sky_net_no'), (['how', 'are', 'you'], 'how_are_you'), (['how', 'are', 'you', 'doing'], 'how_are_you'), (['what', 'is', 'going', 'on'], 'how_are_you'), (['are', 'you', 'good'], 'how_are_you'), (['u', 'good'], 'how_are_you'), (['are', 'u', 'good'], 'how_are_you'), (['are', 'you', 'okay'], 'how_are_you'), (['I', 'am', 'doing', 'great'], 'doing_great'), (['it', 'was', 'a', 'good', 'day'], 'doing_great'), (['I', 'am', 'well'], 'doing_great'), (['Im', 'great'], 'doing_great'), (['awesome'], 'doing_great'), (['happy'], 'doing_great'), (['better'], 'doing_great'), (['fyn'], 'doing_great'), (['fine'], 'doing_great'), (['good', 'day'], 'doing_great'), (['glad', 'to', 'meet', 'you'], 'doing_great'), (['it', 'was', 'so', 'good'], 'doing_great'), (['not', 'great'], 'doing_badly'), (['not', 'well'], 'doing_badly'), (['not', 'good'], 'doing_badly'), (['bad'], 'doing_badly'), (['badly'], 'doing_badly'), (['terrible'], 'doing_badly'), (['horrible'], 'doing_badly'), (['awful'], 'doing_badly'), (['sad'], 'doing_badly'), (['it', 'was', 'so', 'bad'], 'doing_badly'), (['bad', 'day'], 'doing_badly'), (['im', 'so', 'sad'], 'doing_badly'), (['wait', 'you', 'watch', 'Netflix'], 'netflix'), (['how', 'do', 'you', 'watch', 'Netflix'], 'netflix'), (['Netflix'], 'netflix'), (['how', 'can', 'you', 'run'], 'quick_run'), (['how', 'do', 'you', 'run'], 'quick_run'), (['how', 'run'], 'quick_run'), (['why', 'run'], 'quick_run'), (['run'], 'quick_run'), (['you', 'real'], 'real_bot'), (['you', 'human'], 'real_bot'), (['you', 'robot'], 'real_bot'), (['you', 'alive'], 'real_bot'), (['you', 'sentient'], 'real_bot'), (['you', 'conscious'], 'real_bot'), (['tell', 'me', 'joke'], 'joke'), (['got', 'any', 'good', 'jokes'], 'joke'), (['got', 'jokes'], 'joke'), (['can', 'you', 'tell', 'joke'], 'joke'), (['tell', 'joke'], 'joke'), (['haha'], 'good_joke'), (['that', 'was', 'funny'], 'good_joke'), (['very', 'funny'], 'good_joke'), (['good', 'one'], 'good_joke'), (['bad', 'joke'], 'bad_joke'), (['trash', 'joke'], 'bad_joke'), (['terrible'], 'bad_joke'), (['not', 'funny'], 'bad_joke'), (['I', 'hate', 'you'], 'hate'), (['you', 'stupid'], 'hate'), (['you', 'dumb'], 'hate'), (['you', 'mean'], 'hate'), (['i', 'do', \"n't\", 'like', 'you'], 'hate'), (['you', 'my', 'friend'], 'like'), (['I', 'like', 'you'], 'like'), (['I', 'love', 'you'], 'like'), (['you', 'cool'], 'like'), (['you', 'are', 'chill'], 'like'), (['it', 'is', 'nice', 'chatting', 'with', 'you'], 'like'), (['whats', 'favorite', 'show'], 'favorite_show'), (['favorite', 'tv', 'show'], 'favorite_show'), (['Whats', 'favorite', 'movie'], 'favorite_movie'), (['whats', 'favorite', 'film'], 'favorite_movie'), (['best', 'movie'], 'favorite_movie'), (['your', 'favorite', 'movie'], 'favorite_movie'), (['whats', 'your', 'favorite', 'movie'], 'favorite_movie'), (['What', 'think', 'about'], 'your_thoughts'), (['What', 'your', 'thoughts'], 'your_thoughts'), (['i', 'am', 'so', 'scared'], 'fear'), (['that', \"'s\", 'scary'], 'fear'), (['aaaaa'], 'excitement'), (['hkfjj'], 'excitement'), (['gjlfoiodso'], 'excitement'), (['cbbmlkllll'], 'excitement'), (['fieueiioohd'], 'excitement'), (['ohhhhhhhhh'], 'excitement'), (['bbbbb'], 'excitement'), (['cccc'], 'excitement'), (['vvvv'], 'excitement'), (['ddddd'], 'excitement'), (['eeee'], 'excitement'), (['ffff'], 'excitement'), (['ggggg'], 'excitement'), (['hhh'], 'excitement'), (['iiii'], 'excitement'), (['jjjj'], 'excitement'), (['llll'], 'excitement'), (['nnnnn'], 'excitement'), (['pppp'], 'excitement'), (['qqqq'], 'excitement'), (['rrrr'], 'excitement'), (['tttt'], 'excitement'), (['vvvv'], 'excitement'), (['wwww'], 'excitement'), (['xxx'], 'excitement'), (['kkk'], 'character_sp'), (['sss'], 'character_sp'), (['oooo'], 'character_sp'), (['zzzz'], 'character_sl'), (['fine'], 'fine'), (['i', 'am', 'fine'], 'fine'), (['you', 'are', 'cute'], 'cute'), (['you', 'so', 'beautifull'], 'cute'), (['eww'], 'disgust'), (['it', \"'s\", 'so', 'disgusting'], 'disgust'), (['disgust'], 'disgust'), (['disgusting'], 'disgust'), (['it', 'was', 'disgusting'], 'disgust'), (['you', 'are', 'so', 'annoying'], 'angry'), (['you', 'idiot'], 'angry'), ([',', '#', '$', '%', '^', '&'], 'angry'), (['$', '$', '#', '^'], 'angry'), (['%', '%', '$', '#', '^'], 'angry'), (['^', '$', '#', '%'], 'angry'), (['!', '#', '@'], 'angry'), (['i', 'am', 'so', 'ashamed', 'of', 'myself'], 'shame'), (['i', 'am', 'a', 'loser'], 'shame'), (['shame'], 'shame'), (['shame', 'of', 'you'], 'shame'), (['it', \"'s\", 'because', 'of', 'me'], 'guilt'), (['i', 'am', 'the', 'reason'], 'guilt'), (['i', 'am', 'so', 'cruel'], 'guilt'), (['i', 'feel', 'guilty'], 'guilt'), (['guilt'], 'guilt'), (['i', 'am', 'the', 'one', 'to', 'be', 'punished'], 'guilt')]\n",
            "172 documents\n",
            "31 classes ['age', 'angry', 'bad_joke', 'character_sl', 'character_sp', 'cute', 'disgust', 'doing_badly', 'doing_great', 'excitement', 'favorite_movie', 'favorite_show', 'fear', 'fine', 'good_joke', 'goodbye', 'greeting', 'guilt', 'hate', 'how_are_you', 'joke', 'like', 'name', 'netflix', 'quick_run', 'real_bot', 'shame', 'sky_net_no', 'sky_net_yes', 'thanks', 'your_thoughts']\n",
            "182 unique lemmatized words ['#', '$', '%', '&', \"'s\", '@', '^', 'a', 'aaaaa', 'about', 'address', 'age', 'alive', 'am', 'annoying', 'any', 'anyone', 'are', 'ashamed', 'awesome', 'awful', 'bad', 'badly', 'bbbbb', 'be', 'beautifull', 'because', 'best', 'better', 'bye', 'call', 'can', 'cbbmlkllll', 'cccc', 'chatting', 'chill', 'conscious', 'cool', 'cruel', 'cute', 'cya', 'day', 'ddddd', 'disgust', 'disgusting', 'do', 'doe', 'doing', 'dumb', 'eeee', 'eww', 'favorite', 'feel', 'ffff', 'fieueiioohd', 'film', 'fine', 'friend', 'funny', 'fyn', 'ggggg', 'gjlfoiodso', 'glad', 'going', 'good', 'goodbye', 'got', 'great', 'guilt', 'guilty', 'haha', 'hai', 'happy', 'hate', 'have', 'hello', 'helloo', 'hey', 'hhh', 'hi', 'hkfjj', 'hlo', 'hloii', 'horrible', 'how', 'human', 'i', 'idiot', 'iiii', 'im', 'indeed', 'is', 'it', 'jjjj', 'joke', 'kkk', 'later', 'leaving', 'like', 'llll', 'loser', 'love', 'me', 'mean', 'meet', 'movie', 'my', 'myself', \"n't\", 'nah', 'name', 'netflix', 'nice', 'nnnnn', 'no', 'nope', 'not', 'of', 'ohhhhhhhhh', 'okay', 'old', 'on', 'one', 'oooo', 'owe', 'pppp', 'punished', 'qqqq', 'real', 'really', 'reason', 'robot', 'rrrr', 'run', 'sad', 'scared', 'scary', 'see', 'sentient', 'shame', 'should', 'show', 'so', 'ss', 'stupid', 'sup', 'tell', 'terrible', 'thank', 'thanks', 'thankyou', 'that', 'the', 'there', 'think', 'thought', 'to', 'trash', 'tttt', 'tv', 'ty', 'u', 'up', 'very', 'vvvv', 'wa', 'wait', 'watch', 'well', 'what', 'whats', 'why', 'with', 'wwww', 'xxx', 'yeah', 'yep', 'yes', 'you', 'your', 'yup', 'zzzz']\n",
            "Training data created\n",
            "Epoch 1/172\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:70: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "35/35 [==============================] - 1s 2ms/step - loss: 3.4296 - accuracy: 0.0640\n",
            "Epoch 2/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 3.3193 - accuracy: 0.1628\n",
            "Epoch 3/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 3.2258 - accuracy: 0.1453\n",
            "Epoch 4/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 3.1379 - accuracy: 0.1570\n",
            "Epoch 5/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 3.0834 - accuracy: 0.1744\n",
            "Epoch 6/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 2.9909 - accuracy: 0.1860\n",
            "Epoch 7/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 2.8844 - accuracy: 0.2035\n",
            "Epoch 8/172\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 2.7354 - accuracy: 0.2267\n",
            "Epoch 9/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 2.7042 - accuracy: 0.2558\n",
            "Epoch 10/172\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 2.5654 - accuracy: 0.3140\n",
            "Epoch 11/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 2.5039 - accuracy: 0.2965\n",
            "Epoch 12/172\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 2.3396 - accuracy: 0.3256\n",
            "Epoch 13/172\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 2.1742 - accuracy: 0.3779\n",
            "Epoch 14/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 2.0665 - accuracy: 0.3895\n",
            "Epoch 15/172\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 2.0218 - accuracy: 0.4070\n",
            "Epoch 16/172\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 1.9238 - accuracy: 0.4884\n",
            "Epoch 17/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.9421 - accuracy: 0.4302\n",
            "Epoch 18/172\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 1.8179 - accuracy: 0.4709\n",
            "Epoch 19/172\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 1.6786 - accuracy: 0.5116\n",
            "Epoch 20/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.5334 - accuracy: 0.5523\n",
            "Epoch 21/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.4610 - accuracy: 0.5349\n",
            "Epoch 22/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.4705 - accuracy: 0.5814\n",
            "Epoch 23/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.4104 - accuracy: 0.5640\n",
            "Epoch 24/172\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 1.2918 - accuracy: 0.5872\n",
            "Epoch 25/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.2285 - accuracy: 0.6279\n",
            "Epoch 26/172\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 1.3060 - accuracy: 0.5930\n",
            "Epoch 27/172\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 1.0777 - accuracy: 0.6686\n",
            "Epoch 28/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.0459 - accuracy: 0.6744\n",
            "Epoch 29/172\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 1.0802 - accuracy: 0.6977\n",
            "Epoch 30/172\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.9593 - accuracy: 0.7849\n",
            "Epoch 31/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9476 - accuracy: 0.7093\n",
            "Epoch 32/172\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.7917 - accuracy: 0.7907\n",
            "Epoch 33/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9507 - accuracy: 0.6860\n",
            "Epoch 34/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.7698 - accuracy: 0.7733\n",
            "Epoch 35/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6771 - accuracy: 0.8140\n",
            "Epoch 36/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8096 - accuracy: 0.7616\n",
            "Epoch 37/172\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.7655 - accuracy: 0.7267\n",
            "Epoch 38/172\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.6778 - accuracy: 0.7733\n",
            "Epoch 39/172\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.6230 - accuracy: 0.8198\n",
            "Epoch 40/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6067 - accuracy: 0.7965\n",
            "Epoch 41/172\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.6987 - accuracy: 0.7558\n",
            "Epoch 42/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6682 - accuracy: 0.7791\n",
            "Epoch 43/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6540 - accuracy: 0.8023\n",
            "Epoch 44/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5452 - accuracy: 0.8488\n",
            "Epoch 45/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4904 - accuracy: 0.8430\n",
            "Epoch 46/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6226 - accuracy: 0.8198\n",
            "Epoch 47/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5391 - accuracy: 0.8372\n",
            "Epoch 48/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4735 - accuracy: 0.8663\n",
            "Epoch 49/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4263 - accuracy: 0.8721\n",
            "Epoch 50/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5118 - accuracy: 0.8372\n",
            "Epoch 51/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5428 - accuracy: 0.8488\n",
            "Epoch 52/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5423 - accuracy: 0.8488\n",
            "Epoch 53/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3782 - accuracy: 0.9012\n",
            "Epoch 54/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4329 - accuracy: 0.8605\n",
            "Epoch 55/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4181 - accuracy: 0.8721\n",
            "Epoch 56/172\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8779\n",
            "Epoch 57/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4104 - accuracy: 0.8721\n",
            "Epoch 58/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4690 - accuracy: 0.8605\n",
            "Epoch 59/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3391 - accuracy: 0.9186\n",
            "Epoch 60/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4234 - accuracy: 0.8663\n",
            "Epoch 61/172\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.3352 - accuracy: 0.9244\n",
            "Epoch 62/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2872 - accuracy: 0.9012\n",
            "Epoch 63/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3602 - accuracy: 0.8779\n",
            "Epoch 64/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4262 - accuracy: 0.8779\n",
            "Epoch 65/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3734 - accuracy: 0.8837\n",
            "Epoch 66/172\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.3360 - accuracy: 0.9070\n",
            "Epoch 67/172\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.3733 - accuracy: 0.8895\n",
            "Epoch 68/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2973 - accuracy: 0.8953\n",
            "Epoch 69/172\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.2882 - accuracy: 0.9302\n",
            "Epoch 70/172\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.2988 - accuracy: 0.9012\n",
            "Epoch 71/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2834 - accuracy: 0.9128\n",
            "Epoch 72/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3336 - accuracy: 0.8779\n",
            "Epoch 73/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3796 - accuracy: 0.9012\n",
            "Epoch 74/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3231 - accuracy: 0.9244\n",
            "Epoch 75/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3513 - accuracy: 0.8605\n",
            "Epoch 76/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2528 - accuracy: 0.9128\n",
            "Epoch 77/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2308 - accuracy: 0.9419\n",
            "Epoch 78/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3445 - accuracy: 0.8953\n",
            "Epoch 79/172\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2552 - accuracy: 0.9070\n",
            "Epoch 80/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2823 - accuracy: 0.9302\n",
            "Epoch 81/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2769 - accuracy: 0.9128\n",
            "Epoch 82/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2845 - accuracy: 0.8953\n",
            "Epoch 83/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2902 - accuracy: 0.9419\n",
            "Epoch 84/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2359 - accuracy: 0.9302\n",
            "Epoch 85/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2473 - accuracy: 0.9128\n",
            "Epoch 86/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2528 - accuracy: 0.9244\n",
            "Epoch 87/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2689 - accuracy: 0.9070\n",
            "Epoch 88/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2080 - accuracy: 0.9535\n",
            "Epoch 89/172\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.2102 - accuracy: 0.9360\n",
            "Epoch 90/172\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.1905 - accuracy: 0.9302\n",
            "Epoch 91/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2365 - accuracy: 0.9012\n",
            "Epoch 92/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2254 - accuracy: 0.9360\n",
            "Epoch 93/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1936 - accuracy: 0.9419\n",
            "Epoch 94/172\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.2034 - accuracy: 0.9302\n",
            "Epoch 95/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2279 - accuracy: 0.9128\n",
            "Epoch 96/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2306 - accuracy: 0.9244\n",
            "Epoch 97/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2620 - accuracy: 0.9128\n",
            "Epoch 98/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1374 - accuracy: 0.9651\n",
            "Epoch 99/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1616 - accuracy: 0.9535\n",
            "Epoch 100/172\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.2400 - accuracy: 0.9128\n",
            "Epoch 101/172\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.2062 - accuracy: 0.9419\n",
            "Epoch 102/172\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.1640 - accuracy: 0.9535\n",
            "Epoch 103/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1887 - accuracy: 0.9593\n",
            "Epoch 104/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2171 - accuracy: 0.9302\n",
            "Epoch 105/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1862 - accuracy: 0.9477\n",
            "Epoch 106/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1680 - accuracy: 0.9593\n",
            "Epoch 107/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2337 - accuracy: 0.9244\n",
            "Epoch 108/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1705 - accuracy: 0.9419\n",
            "Epoch 109/172\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.2219 - accuracy: 0.9244\n",
            "Epoch 110/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1930 - accuracy: 0.9244\n",
            "Epoch 111/172\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.2027 - accuracy: 0.9186\n",
            "Epoch 112/172\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.2096 - accuracy: 0.9186\n",
            "Epoch 113/172\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.1337 - accuracy: 0.9535\n",
            "Epoch 114/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1774 - accuracy: 0.9419\n",
            "Epoch 115/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1456 - accuracy: 0.9651\n",
            "Epoch 116/172\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.1476 - accuracy: 0.9709\n",
            "Epoch 117/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2548 - accuracy: 0.9128\n",
            "Epoch 118/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2236 - accuracy: 0.9012\n",
            "Epoch 119/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1905 - accuracy: 0.9419\n",
            "Epoch 120/172\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.2167 - accuracy: 0.9302\n",
            "Epoch 121/172\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.2443 - accuracy: 0.8895\n",
            "Epoch 122/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1367 - accuracy: 0.9593\n",
            "Epoch 123/172\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.1807 - accuracy: 0.9477\n",
            "Epoch 124/172\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.1716 - accuracy: 0.9651\n",
            "Epoch 125/172\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.1599 - accuracy: 0.9360\n",
            "Epoch 126/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1607 - accuracy: 0.9419\n",
            "Epoch 127/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2197 - accuracy: 0.9186\n",
            "Epoch 128/172\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.1528 - accuracy: 0.9593\n",
            "Epoch 129/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1592 - accuracy: 0.9419\n",
            "Epoch 130/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1446 - accuracy: 0.9535\n",
            "Epoch 131/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1464 - accuracy: 0.9477\n",
            "Epoch 132/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1206 - accuracy: 0.9651\n",
            "Epoch 133/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1775 - accuracy: 0.9302\n",
            "Epoch 134/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2178 - accuracy: 0.9128\n",
            "Epoch 135/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1779 - accuracy: 0.9419\n",
            "Epoch 136/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1962 - accuracy: 0.9360\n",
            "Epoch 137/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1306 - accuracy: 0.9593\n",
            "Epoch 138/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0983 - accuracy: 0.9826\n",
            "Epoch 139/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1142 - accuracy: 0.9593\n",
            "Epoch 140/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1491 - accuracy: 0.9419\n",
            "Epoch 141/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0830 - accuracy: 0.9884\n",
            "Epoch 142/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1505 - accuracy: 0.9593\n",
            "Epoch 143/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1826 - accuracy: 0.9593\n",
            "Epoch 144/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1430 - accuracy: 0.9477\n",
            "Epoch 145/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2284 - accuracy: 0.9302\n",
            "Epoch 146/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1732 - accuracy: 0.9302\n",
            "Epoch 147/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1474 - accuracy: 0.9593\n",
            "Epoch 148/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.0882 - accuracy: 0.9709\n",
            "Epoch 149/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1178 - accuracy: 0.9593\n",
            "Epoch 150/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1915 - accuracy: 0.9419\n",
            "Epoch 151/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1299 - accuracy: 0.9477\n",
            "Epoch 152/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1955 - accuracy: 0.9535\n",
            "Epoch 153/172\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.1293 - accuracy: 0.9651\n",
            "Epoch 154/172\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.1211 - accuracy: 0.9709\n",
            "Epoch 155/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1618 - accuracy: 0.9244\n",
            "Epoch 156/172\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.1892 - accuracy: 0.9244\n",
            "Epoch 157/172\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.1055 - accuracy: 0.9593\n",
            "Epoch 158/172\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.1474 - accuracy: 0.9477\n",
            "Epoch 159/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1948 - accuracy: 0.9186\n",
            "Epoch 160/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1182 - accuracy: 0.9535\n",
            "Epoch 161/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1280 - accuracy: 0.9709\n",
            "Epoch 162/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1485 - accuracy: 0.9419\n",
            "Epoch 163/172\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.1821 - accuracy: 0.9186\n",
            "Epoch 164/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1159 - accuracy: 0.9709\n",
            "Epoch 165/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1097 - accuracy: 0.9535\n",
            "Epoch 166/172\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.1252 - accuracy: 0.9593\n",
            "Epoch 167/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1854 - accuracy: 0.9244\n",
            "Epoch 168/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1355 - accuracy: 0.9477\n",
            "Epoch 169/172\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.1500 - accuracy: 0.9360\n",
            "Epoch 170/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1886 - accuracy: 0.9302\n",
            "Epoch 171/172\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1255 - accuracy: 0.9593\n",
            "Epoch 172/172\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.1343 - accuracy: 0.9477\n",
            "model created\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout\n",
        "# from keras.optimizers import SGD\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "import random\n",
        "\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "import json\n",
        "import pickle\n",
        "\n",
        "words=[]\n",
        "classes = []\n",
        "documents = []\n",
        "ignore_letters = ['!', '?', ',', '.']\n",
        "intents_file = open('/content/drive/MyDrive/Colab Notebooks/intents.json').read()\n",
        "intents = json.loads(intents_file)\n",
        "\n",
        "for intent in intents['intents']:\n",
        "    for pattern in intent['patterns']:\n",
        "        #tokenize each word\n",
        "        word = nltk.word_tokenize(pattern)\n",
        "        words.extend(word)\n",
        "        #add documents in the corpus\n",
        "        documents.append((word, intent['tag']))\n",
        "        # add to our classes list\n",
        "        if intent['tag'] not in classes:\n",
        "            classes.append(intent['tag'])\n",
        "print(documents)\n",
        "# lemmaztize and lower each word and remove duplicates\n",
        "words = [lemmatizer.lemmatize(w.lower()) for w in words if w not in ignore_letters]\n",
        "words = sorted(list(set(words)))\n",
        "# sort classes\n",
        "classes = sorted(list(set(classes)))\n",
        "# documents = combination between patterns and intents\n",
        "print (len(documents), \"documents\")\n",
        "# classes = intents\n",
        "print (len(classes), \"classes\", classes)\n",
        "# words = all words, vocabulary\n",
        "print (len(words), \"unique lemmatized words\", words)\n",
        "\n",
        "pickle.dump(words,open('words.pkl','wb'))\n",
        "pickle.dump(classes,open('classes.pkl','wb'))\n",
        "\n",
        "# create our training data\n",
        "training = []\n",
        "# create an empty array for our output\n",
        "output_empty = [0] * len(classes)\n",
        "# training set, bag of words for each sentence\n",
        "for doc in documents:\n",
        "    # initialize our bag of words\n",
        "    bag = []\n",
        "    # list of tokenized words for the pattern\n",
        "    pattern_words = doc[0]\n",
        "    # lemmatize each word - create base word, in attempt to represent related words\n",
        "    pattern_words = [lemmatizer.lemmatize(word.lower()) for word in pattern_words]\n",
        "    # create our bag of words array with 1, if word match found in current pattern\n",
        "    for word in words:\n",
        "        bag.append(1) if word in pattern_words else bag.append(0)\n",
        "        \n",
        "    # output is a '0' for each tag and '1' for current tag (for each pattern)\n",
        "    output_row = list(output_empty)\n",
        "    output_row[classes.index(doc[1])] = 1\n",
        "    \n",
        "    training.append([bag, output_row])\n",
        "# shuffle our features and turn into np.array\n",
        "random.shuffle(training)\n",
        "training = np.array(training)\n",
        "# create train and test lists. X - patterns, Y - intents\n",
        "train_x = list(training[:,0])\n",
        "train_y = list(training[:,1])\n",
        "print(\"Training data created\")\n",
        "\n",
        "# Create model - 3 layers. First layer 128 neurons, second layer 64 neurons and 3rd output layer contains number of neurons\n",
        "# equal to number of intents to predict output intent with softmax\n",
        "model = Sequential()\n",
        "model.add(Dense(128, input_shape=(len(train_x[0]),), activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(len(train_y[0]), activation='softmax'))\n",
        "\n",
        "# Compile model. Stochastic gradient descent with Nesterov accelerated gradient gives good results for this model\n",
        "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "\n",
        "#fitting and saving the model \n",
        "hist = model.fit(np.array(train_x), np.array(train_y), epochs=172, batch_size=5, verbose=1)\n",
        "model.save('chatbot_model.h5', hist)\n",
        "\n",
        "print(\"model created\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CpYDixtEhgGZ"
      },
      "outputs": [],
      "source": [
        "import anvil.server"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V3QMp1anhiKB"
      },
      "outputs": [],
      "source": [
        "anvil.server.connect(uplink_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yLZKraGLpUoq"
      },
      "outputs": [],
      "source": [
        "msg = list()\n",
        "text = str()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jY-qqSlY8ifi"
      },
      "outputs": [],
      "source": [
        "@anvil.server.callable\n",
        "def responsed(msg1):\n",
        "    #print(\"response\")\n",
        "    msg.append(msg1)\n",
        "    ints = predict_class(msg1)\n",
        "    res = getResponse(ints, intents)\n",
        "    return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "deibzvJ8WtXw"
      },
      "outputs": [],
      "source": [
        "# # IBM Tone analyzer\n",
        "# import json\n",
        "# from ibm_watson import ToneAnalyzerV3\n",
        "# from ibm_cloud_sdk_core.authenticators import IAMAuthenticator\n",
        "\n",
        "# authenticator = IAMAuthenticator(api_key)\n",
        "# tone_analyzer = ToneAnalyzerV3(\n",
        "#     version='2017-09-21',\n",
        "#     authenticator=authenticator\n",
        "# )\n",
        "\n",
        "# tone_analyzer.set_service_url(https://api.eu-gb.tone-analyzer.watson.cloud.ibm.com/instances/api_key)\n",
        "# text = \" \"\n",
        "# for i in msg:\n",
        "#     text = text+i\n",
        "# tone_analysis = tone_analyzer.tone(\n",
        "#     {'text': text},\n",
        "#     content_type='application/json'\n",
        "# ).get_result()\n",
        "# print(json.dumps(tone_analysis, indent=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CAU4yig57NxI"
      },
      "outputs": [],
      "source": [
        "api_key=\"d750a0e2d5cc68b782de3c02c4100616\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "StHSsHWQk20Q"
      },
      "outputs": [],
      "source": [
        "@anvil.server.callable\n",
        "def song_emotion():\n",
        "    #authenticator = IAMAuthenticator(api_key)\n",
        "   # tone_analyzer = ToneAnalyzerV3(\n",
        "     #   version='2017-09-21',\n",
        "     #   authenticator=authenticator\n",
        "    \n",
        "    #)\n",
        "\n",
        "    #tone_analyzer.set_service_url(https://api.eu-gb.tone-analyzer.watson.cloud.ibm.com/instances/api_key)\n",
        "    # text = \"\"\n",
        "    # for i in msg:\n",
        "    #     text = text+i\n",
        "    len1 = len(msg)    \n",
        "    textData = msg[len1-5]+\". \"+msg[len1-4]+\". \"+msg[len1-3]+\". \"+msg[len1-2]+\". \"+msg[len1-1]\n",
        "    data=te.get_emotion(textData)\n",
        "    emotion=max(data,key=data.get)\n",
        "   # print(\"Data Emotion:\"+emotion)\n",
        "\n",
        "    emoji_dict = {\"joy\":\"Happy\", \"fear\":\"Fear\", \"anger\":\"Angry\", \"sadness\":\"Sad\", \"disgust\":\"Disgust\", \"shame\":\"Shame\", \"guilt\":\"Guilt\"}\n",
        "    texts = [textData]\n",
        "    emotion_counter={\"joy\":0, \"fear\":0, \"anger\":0, \"sadness\":0, \"disgust\":0, \"shame\":0, \"guilt\":0}\n",
        "    for text in msg: \n",
        "        features = create_feature(text, nrange=(1, 4))\n",
        "        features = vectorizer.transform(features)\n",
        "        prediction = clf.predict(features)[0]\n",
        "        #print(text,emoji_dict[prediction])\n",
        "        emotion_=emoji_dict[prediction]\n",
        "        if emotion_.lower()==\"Happy\".lower():\n",
        "            emotion_counter[\"joy\"]=emotion_counter[\"joy\"]+1\n",
        "        elif emotion_.lower()==\"Fear\".lower():\n",
        "            emotion_counter[\"fear\"]=emotion_counter[\"fear\"]+1\n",
        "        elif emotion_.lower()==\"Angry\".lower():\n",
        "            emotion_counter[\"anger\"]=emotion_counter[\"anger\"]+1\n",
        "        elif emotion_.lower()==\"Sad\".lower():\n",
        "            emotion_counter[\"sadness\"]=emotion_counter[\"sadness\"]+1\n",
        "        elif emotion_.lower()==\"Disgist\".lower():\n",
        "            emotion_counter[\"disgust\"]=emotion_counter[\"disgust\"]+1\n",
        "        elif emotion_.lower()==\"Shame\".lower():\n",
        "            emotion_counter[\"shame\"]=emotion_counter[\"shame\"]+1\n",
        "        elif emotion_.lower()==\"Guilt\".lower():\n",
        "            emotion_counter[\"guilt\"]=emotion_counter[\"guilt\"]+1\n",
        "\n",
        "    #print(emotion_counter)\n",
        "    emotion_print=max(emotion_counter,key=emotion_counter.get)\n",
        "    print(emotion)\n",
        "    dic1 = dict()\n",
        "    dic1['emotion'] = emotion\n",
        "    import requests\n",
        "\n",
        "    url=f\"http://ws.audioscrobbler.com/2.0/?method=tag.gettoptracks&tag={emotion}&api_key={api_key}&format=json&limit=10\"\n",
        "    response = requests.get(url)\n",
        "    payload = response.json()\n",
        "    for i in range(10):\n",
        "        r=payload['tracks']['track'][i]\n",
        "        dic1[r['name']] = r['url']\n",
        "    return dic1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OEPKjkc11vSV"
      },
      "outputs": [],
      "source": [
        "def read_data(file):\n",
        "    data = []\n",
        "    with open('/content/drive/MyDrive/Colab Notebooks/text.txt', 'r')as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            label = ' '.join(line[1:line.find(\"]\")].strip().split())\n",
        "            text = line[line.find(\"]\")+1:].strip()\n",
        "            data.append([label, text])\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "guF2W-7Q11Df",
        "outputId": "d0a87922-d126-474f-ba29-1cc308ca585f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of instances: 7480\n"
          ]
        }
      ],
      "source": [
        "file = open('/content/drive/MyDrive/Colab Notebooks/text.txt')\n",
        "data = read_data(file)\n",
        "print(\"Number of instances: {}\".format(len(data)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZMAphU6y2EIe"
      },
      "outputs": [],
      "source": [
        "def ngram(token, n): \n",
        "    output = []\n",
        "    for i in range(n-1, len(token)): \n",
        "        ngram = ' '.join(token[i-n+1:i+1])\n",
        "        output.append(ngram) \n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T6BQm8qK2J2h"
      },
      "outputs": [],
      "source": [
        "def create_feature(text, nrange=(1, 1)):\n",
        "    text_features = [] \n",
        "    text = text.lower() \n",
        "    text_alphanum = re.sub('[^a-z0-9#]', ' ', text)\n",
        "    for n in range(nrange[0], nrange[1]+1): \n",
        "        text_features += ngram(text_alphanum.split(), n)    \n",
        "    text_punc = re.sub('[a-z0-9]', ' ', text)\n",
        "    text_features += ngram(text_punc.split(), 1)\n",
        "    return Counter(text_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xknGPXUL2P2k"
      },
      "outputs": [],
      "source": [
        "def convert_label(item, name): \n",
        "    items = list(map(float, item.split()))\n",
        "    label = \"\"\n",
        "    for idx in range(len(items)): \n",
        "        if items[idx] == 1: \n",
        "            label += name[idx] + \" \"\n",
        "    \n",
        "    return label.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Ywcra962VK4"
      },
      "outputs": [],
      "source": [
        "emotions = [\"joy\", 'fear', \"anger\", \"sadness\", \"disgust\", \"shame\", \"guilt\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "fFoP20qu2RfZ",
        "outputId": "ebe64674-9ab8-489e-c545-3f46a4a0c275"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-5831f9ffa414>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mX_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0my_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0my_all\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memotions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mX_all\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcreate_feature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrange\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
          ]
        }
      ],
      "source": [
        "X_all = []\n",
        "y_all = []\n",
        "for label, text in data:\n",
        "    y_all.append(convert_label(label, emotions))\n",
        "    X_all.append(create_feature(text, nrange=(1, 4)))\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size = 0.2, random_state = 123)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z3NpK2322mf-"
      },
      "outputs": [],
      "source": [
        "\n",
        "def train_test(clf, X_train, X_test, y_train, y_test):\n",
        "    clf.fit(X_train, y_train)\n",
        "    train_acc = accuracy_score(y_train, clf.predict(X_train))\n",
        "    test_acc = accuracy_score(y_test, clf.predict(X_test))\n",
        "    return train_acc, test_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XN8MVZCb28P6"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction import DictVectorizer\n",
        "vectorizer = DictVectorizer(sparse = True)\n",
        "X_train = vectorizer.fit_transform(X_train)\n",
        "X_test = vectorizer.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MCCo2QyD3IUq"
      },
      "outputs": [],
      "source": [
        "svc = SVC()\n",
        "rforest = RandomForestClassifier(random_state=123)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXjAWjfa3SPv",
        "outputId": "cf3d7a49-30b5-4312-bb9d-45cd63752b52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| Classifier                | Training Accuracy | Test Accuracy |\n",
            "| ------------------------- | ----------------- | ------------- |\n",
            "| SVC                       |         0.9067513 |     0.4512032 |\n",
            "joy       (1. 0. 0. 0. 0. 0. 0.)  1084\n",
            "anger     (0. 0. 1. 0. 0. 0. 0.)  1080\n",
            "sadness   (0. 0. 0. 1. 0. 0. 0.)  1079\n",
            "fear      (0. 1. 0. 0. 0. 0. 0.)  1078\n",
            "disgust   (0. 0. 0. 0. 1. 0. 0.)  1057\n",
            "guilt     (0. 0. 0. 0. 0. 0. 1.)  1057\n",
            "shame     (0. 0. 0. 0. 0. 1. 0.)  1045\n"
          ]
        }
      ],
      "source": [
        "clifs = [svc]\n",
        "\n",
        "# train and test them \n",
        "print(\"| {:25} | {} | {} |\".format(\"Classifier\", \"Training Accuracy\", \"Test Accuracy\"))\n",
        "print(\"| {} | {} | {} |\".format(\"-\"*25, \"-\"*17, \"-\"*13))\n",
        "for clf in clifs: \n",
        "    clf_name = clf.__class__.__name__\n",
        "    train_acc, test_acc = train_test(clf, X_train, X_test, y_train, y_test)\n",
        "    print(\"| {:25} | {:17.7f} | {:13.7f} |\".format(clf_name, train_acc, test_acc))\n",
        "\n",
        "l = [\"joy\", 'fear', \"anger\", \"sadness\", \"disgust\", \"shame\", \"guilt\"]\n",
        "l.sort()\n",
        "label_freq = {}\n",
        "for label, _ in data: \n",
        "    label_freq[label] = label_freq.get(label, 0) + 1\n",
        "\n",
        "# print the labels and their counts in sorted order \n",
        "for l in sorted(label_freq, key=label_freq.get, reverse=True):\n",
        "    print(\"{:10}({})  {}\".format(convert_label(l, emotions), l, label_freq[l]))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "id": "9NmNj_qN3cJx",
        "outputId": "8714381c-3547-4b32-f457-2546f1ff0118"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Chatbot : Hey there, Wassup ?\n",
            "User : hello\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-d3905b8c9877>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"User : \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponsed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Chatbot : \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msong_emotion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-b4b7625f5333>\u001b[0m in \u001b[0;36mresponsed\u001b[0;34m(msg1)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m#print(\"response\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mints\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetResponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-d8c416545e60>\u001b[0m in \u001b[0;36mpredict_class\u001b[0;34m(sentence)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;31m# filter below  threshold predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbag_of_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshow_details\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0mERROR_THRESHOLD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.25\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0mERROR_THRESHOLD\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    100\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type NoneType)."
          ]
        }
      ],
      "source": [
        "UserRp=\"yes\"\n",
        "while UserRp.lower()==\"yes\":\n",
        "    print(\"Chatbot : Hey there, Wassup ?\")\n",
        "    # responded function takes text of user and returns chatbot output\n",
        "    for i in range(0,5):\n",
        "        m = input(\"User : \")\n",
        "        res = responsed(m)\n",
        "        print(\"Chatbot : \"+res)\n",
        "    ans = song_emotion()\n",
        "    print(\"Emotion : \"+ans['emotion'])\n",
        "    UserRp = input(\"Chat Again Yes / No : \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zt38OzQXt_Lz"
      },
      "outputs": [],
      "source": [
        "# print(msg)\n",
        "# # print(text)\n",
        "# print(len(msg))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q18XH1RWpAXV"
      },
      "outputs": [],
      "source": [
        "# SONG RECOMMENDATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8N4bfBmXnBkm",
        "outputId": "2371b8a4-c57a-4800-8392-21eed490b235"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'tracks': {'track': [{'name': 'Pumped Up Kicks', 'duration': '236', 'mbid': '816b3284-5f24-4f3a-9554-750e0bf5d060', 'url': 'https://www.last.fm/music/Foster+the+People/_/Pumped+Up+Kicks', 'streamable': {'#text': '0', 'fulltrack': '0'}, 'artist': {'name': 'Foster the People', 'mbid': 'e0e1a584-dd0a-4bd1-88d1-c4c62895039d', 'url': 'https://www.last.fm/music/Foster+the+People'}, 'image': [{'#text': 'https://lastfm.freetls.fastly.net/i/u/34s/2a96cbd8b46e442fc41c2b86b821562f.png', 'size': 'small'}, {'#text': 'https://lastfm.freetls.fastly.net/i/u/64s/2a96cbd8b46e442fc41c2b86b821562f.png', 'size': 'medium'}, {'#text': 'https://lastfm.freetls.fastly.net/i/u/174s/2a96cbd8b46e442fc41c2b86b821562f.png', 'size': 'large'}, {'#text': 'https://lastfm.freetls.fastly.net/i/u/300x300/2a96cbd8b46e442fc41c2b86b821562f.png', 'size': 'extralarge'}], '@attr': {'rank': '1'}}, {'name': \"I'm Yours\", 'duration': '242', 'mbid': 'a5a2330e-2fff-4601-a715-6e68a8e98fbf', 'url': 'https://www.last.fm/music/Jason+Mraz/_/I%27m+Yours', 'streamable': {'#text': '0', 'fulltrack': '0'}, 'artist': {'name': 'Jason Mraz', 'mbid': '82eb8936-7bf6-4577-8320-a2639465206d', 'url': 'https://www.last.fm/music/Jason+Mraz'}, 'image': [{'#text': 'https://lastfm.freetls.fastly.net/i/u/34s/2a96cbd8b46e442fc41c2b86b821562f.png', 'size': 'small'}, {'#text': 'https://lastfm.freetls.fastly.net/i/u/64s/2a96cbd8b46e442fc41c2b86b821562f.png', 'size': 'medium'}, {'#text': 'https://lastfm.freetls.fastly.net/i/u/174s/2a96cbd8b46e442fc41c2b86b821562f.png', 'size': 'large'}, {'#text': 'https://lastfm.freetls.fastly.net/i/u/300x300/2a96cbd8b46e442fc41c2b86b821562f.png', 'size': 'extralarge'}], '@attr': {'rank': '2'}}, {'name': 'Dog Days Are Over', 'duration': '270', 'mbid': '772ea437-45b3-4868-b3c0-b80526ef0fa3', 'url': 'https://www.last.fm/music/Florence+%252B+the+Machine/_/Dog+Days+Are+Over', 'streamable': {'#text': '0', 'fulltrack': '0'}, 'artist': {'name': 'Florence + the Machine', 'mbid': '5fee3020-513b-48c2-b1f7-4681b01db0c6', 'url': 'https://www.last.fm/music/Florence+%252B+the+Machine'}, 'image': [{'#text': 'https://lastfm.freetls.fastly.net/i/u/34s/2a96cbd8b46e442fc41c2b86b821562f.png', 'size': 'small'}, {'#text': 'https://lastfm.freetls.fastly.net/i/u/64s/2a96cbd8b46e442fc41c2b86b821562f.png', 'size': 'medium'}, {'#text': 'https://lastfm.freetls.fastly.net/i/u/174s/2a96cbd8b46e442fc41c2b86b821562f.png', 'size': 'large'}, {'#text': 'https://lastfm.freetls.fastly.net/i/u/300x300/2a96cbd8b46e442fc41c2b86b821562f.png', 'size': 'extralarge'}], '@attr': {'rank': '3'}}, {'name': 'A-Punk', 'duration': '136', 'mbid': '047db898-cedf-48a0-afc2-5b686c9b8840', 'url': 'https://www.last.fm/music/Vampire+Weekend/_/A-Punk', 'streamable': {'#text': '0', 'fulltrack': '0'}, 'artist': {'name': 'Vampire Weekend', 'mbid': 'af37c51c-0790-4a29-b995-456f98a6b8c9', 'url': 'https://www.last.fm/music/Vampire+Weekend'}, 'image': [{'#text': 'https://lastfm.freetls.fastly.net/i/u/34s/2a96cbd8b46e442fc41c2b86b821562f.png', 'size': 'small'}, {'#text': 'https://lastfm.freetls.fastly.net/i/u/64s/2a96cbd8b46e442fc41c2b86b821562f.png', 'size': 'medium'}, {'#text': 'https://lastfm.freetls.fastly.net/i/u/174s/2a96cbd8b46e442fc41c2b86b821562f.png', 'size': 'large'}, {'#text': 'https://lastfm.freetls.fastly.net/i/u/300x300/2a96cbd8b46e442fc41c2b86b821562f.png', 'size': 'extralarge'}], '@attr': {'rank': '4'}}, {'name': \"Friday I'm in Love\", 'duration': '214', 'mbid': '8d9104c6-7d8e-460b-8c3d-2d797f79953d', 'url': 'https://www.last.fm/music/The+Cure/_/Friday+I%27m+in+Love', 'streamable': {'#text': '0', 'fulltrack': '0'}, 'artist': {'name': 'The Cure', 'mbid': '69ee3720-a7cb-4402-b48d-a02c366f2bcf', 'url': 'https://www.last.fm/music/The+Cure'}, 'image': [{'#text': 'https://lastfm.freetls.fastly.net/i/u/34s/2a96cbd8b46e442fc41c2b86b821562f.png', 'size': 'small'}, {'#text': 'https://lastfm.freetls.fastly.net/i/u/64s/2a96cbd8b46e442fc41c2b86b821562f.png', 'size': 'medium'}, {'#text': 'https://lastfm.freetls.fastly.net/i/u/174s/2a96cbd8b46e442fc41c2b86b821562f.png', 'size': 'large'}, {'#text': 'https://lastfm.freetls.fastly.net/i/u/300x300/2a96cbd8b46e442fc41c2b86b821562f.png', 'size': 'extralarge'}], '@attr': {'rank': '5'}}], '@attr': {'tag': 'happy', 'page': '1', 'perPage': '5', 'totalPages': '4509', 'total': '22543'}}}\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "\n",
        "url=f\"http://ws.audioscrobbler.com/2.0/?method=tag.gettoptracks&tag=happy&api_key={api_key}&format=json&limit=5\"\n",
        "response = requests.get(url)\n",
        "payload = response.json()\n",
        "# for i in range(4):\n",
        "r=payload['tracks']['track'][0]\n",
        "# print(r['url'])\n",
        "print(payload)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zio9sPymm7kF"
      },
      "outputs": [],
      "source": [
        "# print(dic1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O4yla2WTHiGz",
        "outputId": "d70a8db9-2090-4a8b-d8ea-1884d703f3e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Happy\n",
            "Emotion : Happy\n",
            "Song Recommendations : \n",
            "Song_name : Pumped Up Kicks\n",
            "Song_URL : https://www.last.fm/music/Foster+the+People/_/Pumped+Up+Kicks\n",
            "Song_name : I'm Yours\n",
            "Song_URL : https://www.last.fm/music/Jason+Mraz/_/I%27m+Yours\n",
            "Song_name : Dog Days Are Over\n",
            "Song_URL : https://www.last.fm/music/Florence+%252B+the+Machine/_/Dog+Days+Are+Over\n",
            "Song_name : A-Punk\n",
            "Song_URL : https://www.last.fm/music/Vampire+Weekend/_/A-Punk\n",
            "Song_name : Friday I'm in Love\n",
            "Song_URL : https://www.last.fm/music/The+Cure/_/Friday+I%27m+in+Love\n",
            "Song_name : Float On\n",
            "Song_URL : https://www.last.fm/music/Modest+Mouse/_/Float+On\n",
            "Song_name : Island in the Sun\n",
            "Song_URL : https://www.last.fm/music/Weezer/_/Island+in+the+Sun\n",
            "Song_name : Hey Ya!\n",
            "Song_URL : https://www.last.fm/music/OutKast/_/Hey+Ya%21\n",
            "Song_name : Don't Stop Me Now\n",
            "Song_URL : https://www.last.fm/music/Queen/_/Don%27t+Stop+Me+Now\n",
            "Song_name : Young Folks\n",
            "Song_URL : https://www.last.fm/music/Peter+Bjorn+and+John/_/Young+Folks\n"
          ]
        }
      ],
      "source": [
        "# song_emotion function would return dictionary consisting of emotion and recommended songs\n",
        "ans = song_emotion()\n",
        "print(\"Emotion : \"+ans['emotion'])\n",
        "ans.pop('emotion')\n",
        "lst = list(ans.keys())\n",
        "print(\"Song Recommendations : \")\n",
        "for i in range(10):\n",
        "    print(\"Song_name : \"+lst[i])\n",
        "    print(\"Song_URL : \"+ans[lst[i]])\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "orginal of chatbot song recommender system.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}